{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis\n",
    "\n",
    "Latent Semantic Analysis (LSA), a high-dimensional linear associative model that embodies no human knowledge beyond its general learning mechanism , to analyze a large corpus of natural text and generate a representation that captures the similarity of words and text passages.\n",
    "\n",
    "From: *Landauer, Thomas & Dumais Susan (1997).* A solution to Plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Setting up an example 'bag of words' DataFrame. The real data would come from analysing the word occurences in different text samples, or 'contexts'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "words = np.array([\n",
    "    [1,1,1,0,0],\n",
    "    [3,3,3,0,0],\n",
    "    [4,4,4,0,0],\n",
    "    [5,5,5,0,0],\n",
    "    [0,2,0,4,4],\n",
    "    [0,0,0,5,5],\n",
    "    [0,1,0,2,2]])\n",
    "\n",
    "idx = ['word'+str(i) for i in range(1,8)]\n",
    "col = ['context'+str(i) for i in range(1,6)]\n",
    "A = pd.DataFrame(data=words, index=idx, columns=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data\n",
    "The example 'bag of words' now looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       context1  context2  context3  context4  context5\n",
      "word1         1         1         1         0         0\n",
      "word2         3         3         3         0         0\n",
      "word3         4         4         4         0         0\n",
      "word4         5         5         5         0         0\n",
      "word5         0         2         0         4         4\n",
      "word6         0         0         0         5         5\n",
      "word7         0         1         0         2         2\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "At the heart of the LSA is a dimensionality reduction technique called: **Singular Value Decomposition (SVD)**\n",
    "\n",
    "Perfoming the SVD on the example matrix using the numpy.svd() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, E, V = np.linalg.svd(A.values, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the following matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1376 -0.0236 -0.0108  0.5601 -0.3757]\n",
      " [-0.4128 -0.0708 -0.0324  0.2064  0.756 ]\n",
      " [-0.5504 -0.0944 -0.0432 -0.7248 -0.1846]\n",
      " [-0.688  -0.1181 -0.054   0.344  -0.2308]\n",
      " [-0.1528  0.5911  0.6537  0.      0.2   ]\n",
      " [-0.0722  0.7313 -0.6782  0.      0.    ]\n",
      " [-0.0764  0.2956  0.3268  0.     -0.4   ]]\n",
      "\n",
      "[ 12.481    9.5086   1.3456   0.       0.    ]\n",
      "\n",
      "[[-0.5623 -0.5929 -0.5623 -0.0901 -0.0901]\n",
      " [-0.1266  0.0288 -0.1266  0.6954  0.6954]\n",
      " [-0.4097  0.8048 -0.4097 -0.0913 -0.0913]\n",
      " [-0.7071  0.      0.7071  0.      0.    ]\n",
      " [ 0.     -0.      0.     -0.7071  0.7071]]\n"
     ]
    }
   ],
   "source": [
    "print(U, E, V, sep=2*'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "Now doing some kick-ass dimensionality reduction by removing the weakest 'concept' in the singular value matrix 'E':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12.481    9.5086   0.       0.       0.    ]\n"
     ]
    }
   ],
   "source": [
    "E[2] = 0.0\n",
    "\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reconstruct the original matrix A with the reduced matrix E.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.994   1.0117  0.994  -0.0013 -0.0013]\n",
      " [ 2.9821  3.0351  2.9821 -0.004  -0.004 ]\n",
      " [ 3.9762  4.0468  3.9762 -0.0053 -0.0053]\n",
      " [ 4.9702  5.0585  4.9702 -0.0066 -0.0066]\n",
      " [ 0.3603  1.2922  0.3603  4.0803  4.0803]\n",
      " [-0.3739  0.7344 -0.3739  4.9167  4.9167]\n",
      " [ 0.1802  0.6461  0.1802  2.0401  2.0401]]\n"
     ]
    }
   ],
   "source": [
    "A2 = np.dot(np.dot(U, np.diag(E)), V)\n",
    "\n",
    "print(A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "The vectors in the new matrix A2 can now be compared using the cosine similarity.\n",
    "\n",
    "$$cos(\\pmb x, \\pmb y) = \\frac {\\pmb x \\cdot \\pmb y}{||\\pmb x|| \\cdot ||\\pmb y||}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3603  1.2922  0.3603  4.0803  4.0803]\n",
      "[-0.3739  0.7344 -0.3739  4.9167  4.9167]\n",
      "0.980428708498\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return sum([i*j for i,j in zip(a, b)])/(math.sqrt(sum([i*i for i in a]))* math.sqrt(sum([i*i for i in b])))\n",
    "\n",
    "print(A2[4], A2[5], sep='\\n')\n",
    "print(cosine_similarity(A2[4], A2[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.994   1.0117  0.994  -0.0013 -0.0013]\n",
      "[-0.3739  0.7344 -0.3739  4.9167  4.9167]\n",
      "-0.0010928254832\n"
     ]
    }
   ],
   "source": [
    "print(A2[0], A2[5], sep='\\n')\n",
    "print(cosine_similarity(A2[0], A2[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
